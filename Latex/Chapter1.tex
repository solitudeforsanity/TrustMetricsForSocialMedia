\part{Background}
\chapter{Introduction}
In this Chapter we give you an explanation of the purpose of study and the research questions we would address. We also give the motivation and aim of the project followed by the goals that should be achieved at the end of this research and finally give a brief overview of how this thesis is structured. 
\section{Motivation}
Online interactions represent a complex blend of human actors and technological systems[2]. In recent years, the type of content on the web has transformed greatly and the interactions online between human actors has become increasingly popular. A big contributor to this is social media networks such as Facebook, Twitter and Google Plus and Question and Answer platforms like Yahoo Answers, Quora and Stackoverflow which act as public boards of discussion.  Opinions are frequently posted to social media sites and are often a mixture of fact, speculation or rumour whereas user-driven sites such as Wikipedia are often questioned for their trustworthiness[4]. Blogs are used as sound boards for average users to disseminate information to their social circles and favourable opinion becomes fact which in turn is regarded as trustworthy information. \\*\\*
Todays brands place a lot of trust in opinions on social media, use social media to learn from their audience and have integrated social media into their business model. Whilst the scale and variety of information has considerable value for commercial and social purposes, the quality, provenance, trust and validity is often questionable[1]. It is impossible for us as human beings to manually verify every piece of information presented to us on social media. It is also not possible to make an informed judgement on the trustworthiness of a person,account or entity online. Verified Twitter and Facebook profiles go some way to ensure that the identity of an entity is verified independently therefore ensuring the authenticity of that entity. However, this does not go far enough in making sure that the information on social networks is truly accurate and therefore trustworthy. Trust can be quantified through the creation of algorithms and quality metrics which can be used to address the issues of validity and quality through the use of automated assessments. These metrics would be used to identify different aspects of an informational source and look for independent verification of the quality of the data. The metrics would need to be tested against real-world examples and vary depending on the platforms (e.g : Twitter, Facebook) and the situation/context. (e.g : Movie ratings might have different metrics and weights to a crisis situation); the nuances of language can change the meaning of a piece of information drastically through the use of slightly different words. An example of this would be \textsl{"We anticipate the latest release to be announced shortly"} versus \textsl{"We expect the latest release to be announced shortly"}. Although the words are synonyms, the first sentence regards the release as something that is probable. The second sentence regards the release to be more of a certainty.
\\*\\*
Another reason why trust metrics is important is because of the huge difference in variance in user-generated content consumed by everyone today as opposed to traditional content published by news websites which was the main source of information back in the day[5]. This is particularly significant in knowledge based media such as twitter and question and answer platforms where you could have very high quality trustworthy content to low quality, untrustworthy and sometimes abusive content[5].\\*\\*
Trust is also a primary factor in influence and social media is now heavily relied upon as a source of information. This can vary from international breaking news to booking the next holiday. The common factor is that the information is often based on people's experiences that are then shared online. Trustworthiness then becomes of paramount importance especially considering the fact that something that becomes popular on the internet is not necessarily true and vice versa. 
\section{Aim}
The aim of this work is to provide a systematic method of verifying information on the internet, specifically on twitter, independently and create a more trustworthy online experience. There has been a lot of research done in this area, which we will detail in the next section, however our approach is novel in that it specifically studies the features of news websites. Our assumption being that official news websites are trustworthy and then studies the features of some known untrustworthy twitter pages and uses this knowledge to predict the trustworthiness of tweets that it's fed. This project will help improve upon current research and look at alternative solutions than those that are proposed and provide an implementation to test these out which we believe will help brands, people and the whole of the digital world to have a better online experience. 

\section{Goals}
In this project we address the task of classifying information as trustworthy or not on Twitter. We focus on the following research questions and goals : \\*\\*
1. Identify the factors that affect trustworthiness in Online Social media and narrow it down to the factors that could be important in the case of Twitter. \\*\\*
2. Data Gathering - Collect Trustworthy and Untrustworthy tweets for analysis and verification.\\*\\*
3. Implement a Machine Learning model and try and improve the accuracy of prediction of this model by tweaking features, adding more features that could be inferred from the features that were collected from the Twitter API, etc to give us an accuracy of 80\% or more if possible.\\*\\*
4. Compare this with other models to pick the best model for this problem. \\*\\*
5. Verify the prediction of model by using new data.
\section{Thesis Structure}
$\textbf{Chapter 1}$ We first give a introduction and overview of the project, identify the goals and purpose as well as provide a motivation behind it.\\*\\*
$\textbf{Chapter 2}$ Provides some background into the research already done in related areas, in different domains but with similar ideas. \\*\\*
$\textbf{Chapter 3}$ This chapter looks specifically at Logistic Regression which was a Machine Learning Technique we used. \\*\\*
$\textbf{Chapter 4}$ We look at the theory behind Support Vector Machines in this Chapter which was the second Machine Learning Technique used. \\*\\*
$\textbf{Chapter 5}$ The method and approach to the problem is discussed here. \\*\\*
$\textbf{Chapter 7}$ Implementation Details are discussed.  \\*\\*
$\textbf{Chapter 8}$ Testing and results are discussed here.  \\*\\*
$\textbf{Chapter 9}$ Reflections, Conclusion, challenges and future work would conclude this thesis.  \\*\\*