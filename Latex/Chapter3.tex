\part{Contributions}
\chapter{Approach to the Problem}
In this chapter, we detail our scope and approach to the Trustworthiness assessment problem, along with the assumptions we made. Our aim is to develop a Machine Learning model that determines the Trustworthiness factor of a tweet to a reasonable level of accuracy. In the next section we scope our problem, and provide justifications for the chosen platform.   
\section{Methodology}
\subsection{Scope}
The focus of our research is assessing the trustworthiness of information published via by social media. As explained in Section 1, Social Media Networks vary greatly in terms of how they are used as well as the purpose the platform serves. Considering this fact a broad solution would not be practical or appropriate. We considered the different types of social media platforms available, the previous research conducted on each of these networks and the developments made. From this, we concluded that Twitter was the best platform to work with. Specific reasons are outlined below : 
\begin{itemize}
\item Twitter is a simple and yet powerful platform and is used widely and regularly by millions of people around the world. 
\item The fact that unlike some of the other social media platforms, Twitter feeds are most often public, hence reaching a wider audience. This would be useful in two ways. One of which is the fact that because the reach is wide spread our research would make more sense. The other is that, since most tweets are public, it would be much more easily accessible for our research. 
\item The well developed, documented and relatively open Application Programming Interface(API) which would be used to retrieve Twitter feeds and features. 
\item The restricted form of text, i.e the 140 characters allowed in a Twitter post, provides us with a solid structure to work with which would make it easier for comparison of tweets.
\item In the Facebook Vs Twitter debate, Twitter was the clear winner since Facebook is built on the idea of connecting friends while twitter is designed for people from all over the world who haven't met to carry on a global conversation\cite{22}. This closely aligned with our research goals hence the choice. 
\end{itemize}
We limit our scope to Twitter such that we have a specific platform and problem to deal with. 
\section{Approach Detailed}

\begin{tikzpicture}[node distance=0cm]

\node (step1) [startstop, text width=4cm] {STEP 1 : Defining and Gathering Trustworthy + Untrustworthy data};
\node (step2) [startstop, right of=step1, xshift=5.5cm, text width=4cm] {STEP 2 : Data formatting and Storage };
\node (step3) [startstop, right of=step2, xshift=5.5cm, text width=4cm] {STEP 3 : Extracting / Identifying features of the Data  };
\node (step4) [startstop, below of=step2, text width=6cm, yshift=-4.2cm] {STEP 4 : Applying Machine Learning to the gathered data and using the data and identified features to train the Supervised Machine Learning model };
\node (step5) [startstop, left of=step4, below of=step1, text width=4cm, yshift=-8.5cm] {STEP 5 : Internal testing of created model to see if it can use features of data to predict Trustworthiness or Untrustworthiness };
\node (step6) [startstop, right of=step5, xshift=5.5cm, text width=4cm] {STEP 6 : Gathering new data of Trustworthy and Untrustworthy tweets };
\node (step7) [startstop, right of=step6, xshift=5.5cm, text width=4cm] {STEP 7 : Evaluating model ability to accurately predict };
\draw [arrow] (step1) -- (step2);
\draw [arrow] (step2) -- (step3);
\draw [arrow] (step3) -- (step4);
\draw [arrow] (step4) -- (step5);
\draw [arrow] (step5) -- (step6);
\draw [arrow] (step6) -- (step7);
\end{tikzpicture}

Once we defined the scope, our next task was exploring whether using news agency tweets to learn from, for trustworthiness prediction was a good solution or not. 
We assumed that Tweets by News agencies would be trustworthy. We selected 20 popular news Twitter feeds from which we collected tweets. The News Websites are : The Independent, New York Times, The Guardian, The Economist, USA Today, Bloomberg News, Associate Press, MSNBC, Forbes, The Financial Times, BBC World, Times of India, Reuters, Wall Street Journal, CNET, CBSNews, Huffington Post, The Daily Telegraph, CNN and ABC. We restricted the trustworthy news websites to the English speaking world, for simplicity in analysis.\\*\\*
Our next task was identifying untrustworthy tweets.  Our second assumption is that known fake accounts are Untrustworthy. This task was slightly more difficult than the previous since, finding many known, Untrustworthy Twitter feeds proved harder. However, we used some of the fake Twitter websites which post Untrustworthy information for our bad tweets. These untrustworthy websites were suggested by \cite{23} and \cite{24} and we manually verified a subset of the tweets. The following Twitter pages were classified as Untrustworthy : PrinceTweets2u, Jesus\_M\_Christ, SeinfeldToday, FakeYahooNews, newsthump, notzuckerberg, NotSportsCenter, FakeAPStyleBook, TomHankThatsMe, NYOnIt, TheFakeCNN, BBCSporf, feinisttswift, TheOnion, Kimkierkegaard, SadPaulGiamatti, NotCoatFactory, FakeSteranko, Bill\_Nye\_Tho, Seinfeld2000, PinterestFake, TheFakeESPN, BBCMews, FakeSTCom. \\*\\* An example of the Untrustworthy tweet gathered is given below : \\*\\*
\centerline{\textit{``The Queen reportedly fuming that Fathers4Justice have made it onto}} 
\centerline{\textit{the palace roof and then have the audacity to sing?badly. More to follow.''}}\leavevmode \\\\
STEP 1 : Once we decided the Twitter profiles that we would use for data collection we set about collecting the data using our own code which interfaced with the Twitter API. 
STEP 2 : The next task was formatting the data for our requirements. The next chapter provides more detail on data collection and manipulation. 
STEP 3 : We then had to extract features that we would need to pass on to the Machine Learning model. We had to chose these features based on how helpful these features would be for our classification task. For this, our background reading and literature review helped in order to weed out factors and features that may not be important to the ones that might be important.
STEP 4 :  We train and test using our original dataset on three different machine learning models, namely Support Vector Machines\footnote{see Section 5.3}, Logistic Regression\footnote{see Section 5.2} and Random Forests\footnote{see Section 5.4} and measure the accuracy rate. More details on the Machine Learning models and Experiment are given in the following chapters. 
STEP 5 : We now train and test our data each time tweaking some features or the parameters passed into the Machine Learning models to receive a positive prediction score. 
STEP 6 : We gather more data for our external testing. This is done by handpicking known Trustworthy and Untrustworthy data. Trustworthy data was news Twitter pages that have not been used in the analysis before and Untrustworthy tweets were tweets that were posted during crisis situations which later papers condemn or mention and deem Untrustworthy. 
STEP 7 : We then chose the best method and feed in some raw data, that the model would have not seen before, for it to determine the Classification of the tweets. The following chapters elaborate on this. \\*\\*
